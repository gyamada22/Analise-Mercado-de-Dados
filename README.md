
#  AnÃ¡lise do Mercado de Dados: Resumo do Projeto

---

## 1. Metodologia
O projeto mapeou o mercado de dados brasileiro atravÃ©s da extraÃ§Ã£o de informaÃ§Ãµes de vagas reais, utilizando IA para converter descriÃ§Ãµes textuais em mÃ©tricas de competÃªncias classificadas como **ObrigatÃ³rio** ou **Diferencial**.

---

## 2. EvoluÃ§Ã£o por Senioridade

<p align="center">
  <img src="./docs/images/junior_project.png" width="700">
</p>

###  JÃºnior (101 Vagas)
* **Base [ObrigatÃ³rio]:** DomÃ­nio de **Power BI** (27,36%), Excel AvanÃ§ado (20,27%) e SQL (18,58%).
* **[Diferencial] de Destaque:** **Bibliotecas Python** (8,85%) e Tableau (5,31%) aparecem como as principais ferramentas para superar a concorrÃªncia inicial.
* **VisÃ£o TÃ©cnica:** Sem a trÃ­ade bÃ¡sica, **Bibliotecas Python (Pandas, NumPy)** (14,16%) e ETL (6,44%) lideram a lista de exigÃªncias.

###  Pleno (137 Vagas)
* **MigraÃ§Ã£o TÃ©cnica [ObrigatÃ³rio]:** **Power BI** (37,50%) e SQL (35,81%) continuam fortes, mas o **Python** (28,38%) torna-se um pilar de sustentaÃ§Ã£o.
* **O Valor do Tableau:** Ocupa um papel estratÃ©gico como **[Diferencial]** (7,21%) e sua obrigatoriedade tÃ©cnica salta para 10,73% quando ignoramos as ferramentas bÃ¡sicas.
* **Novos Requisitos:** ETL e Machine Learning surgem como diferenciais crÃ­ticos (9,91% cada).

###  SÃªnior (64 Vagas)
* **Arquitetura e Escala [ObrigatÃ³rio]:** O foco muda para Cloud (AWS 10,34% como diferencial) e Big Data (9,48%).
* **EspecializaÃ§Ã£o:** O ETL atinge seu maior nÃ­vel de obrigatoriedade tÃ©cnica (13,26%).
* **GovernanÃ§a e OrquestraÃ§Ã£o:** Machine Learning (8,60%), Git (3,94%) e **Apache Airflow** consolidam-se como requisitos para lideranÃ§a de projetos.

---

## 3. O Peso EstratÃ©gico do Tableau
Embora o **Power BI** seja a ferramenta universal em volume, o Tableau Ã© identificado nos dados como o principal "divisor de Ã¡guas". Ele atinge seu pico de importÃ¢ncia no nÃ­vel Pleno, onde Ã© o terceiro maior diferencial (7,21%) e apresenta uma obrigatoriedade tÃ©cnica de 10,73% para vagas que buscam especializaÃ§Ã£o fora do ecossistema Microsoft.

---

## 4. RecomendaÃ§Ãµes de Carreira (Pathing)

1.  **InÃ­cio (JÃºnior):** Foque em **Power BI** e SQL, mas estude Tableau para entrar no grupo de elite com diferenciais tÃ©cnicos.
2.  **Meio (Pleno):** Domine **Bibliotecas Python** (Pandas, NumPy) e processos de ETL. Use o Tableau para visualizaÃ§Ãµes de maior complexidade e performance.
3.  **Fim (SÃªnior):** Direcione o aprendizado para arquitetura em Nuvem (AWS/Azure) e **OrquestraÃ§Ã£o** de grandes volumes de dados com **Apache Airflow**.

---

## 5. ConclusÃ£o
A anÃ¡lise demonstra que o profissional deve evoluir de um perfil de "consumo de dados" (JÃºnior/BI) para um perfil de "construÃ§Ã£o de arquitetura" (SÃªnior/ETL/Cloud). O Tableau atua como uma ponte estratÃ©gica nessa evoluÃ§Ã£o, oferecendo um diferencial competitivo sÃ³lido para quem busca posiÃ§Ãµes de maior senioridade e especializaÃ§Ã£o tÃ©cnica.






















-------------------------------------
# Job Market Analysis 

## ğŸ–¥ï¸ DescriÃ§Ã£o do Projeto
- Este projeto tem como objetivo analisar **vagas reais de emprego na Ã¡rea de dados**, coletadas a partir de plataformas de recrutamento (ex: LinkedIn), para extrair insights sobre **skills demandadas, tendÃªncias do mercado e gaps de competÃªncias**.

- A anÃ¡lise Ã© inicialmente focada no **mercado brasileiro**, com posterior **comparaÃ§Ã£o com dados internacionais**, visando identificar padrÃµes globais e possÃ­veis tendÃªncias que podem chegar ao Brasil no futuro.

- O projeto transforma dados nÃ£o estruturados em **insights analÃ­ticos e dashboards interativos**, documentando todo o pipeline de dados de forma clara e profissional.

---

## ğŸ”¹ Coleta de Dados
> **Desafio:** LinkedIn possui API fechada, impossibilitando a coleta automatizada de vagas diretamente via Python.

> **SoluÃ§Ã£o:** Para contornar, coletei os dados manualmente, visitando cada vaga e usando prompts de IA para extrair informaÃ§Ãµes estruturadas (empresa, cargo, localizaÃ§Ã£o, data e skills).

Essa abordagem garantiu **eficiÃªncia e confiabilidade** para o pipeline subsequente.

---

## ğŸ› ï¸ Tecnologias e Ferramentas

O fluxo do projeto segue:

**Coleta** ![IA](https://img.shields.io/badge/IA-AI-blue) âŸ¶ **VisualizaÃ§Ã£o** ![Excel](https://img.shields.io/badge/Excel-217346?style=flat&logo=microsoft-excel&logoColor=white) âŸ¶ **Limpeza** ![Python](https://img.shields.io/badge/Python-3670A0?style=flat&logo=python&logoColor=white) âŸ¶ **AnÃ¡lise** ![SQL](https://img.shields.io/badge/SQL-4479A1?style=flat&logo=mysql&logoColor=white) âŸ¶ **ApresentaÃ§Ã£o** ![Power BI](https://img.shields.io/badge/Dashboard-F2C811?style=flat&logo=power-bi&logoColor=black) âŸ¶ **DocumentaÃ§Ã£o** ![GitHub](https://img.shields.io/badge/GitHub-181717?style=flat&logo=github&logoColor=white)

| Etapa | Ferramenta | FunÃ§Ã£o |
|-------|------------|------|
| Coleta & extraÃ§Ã£o | IA via prompts | Extrai dados estruturados da vaga |
| VisualizaÃ§Ã£o inicial | Excel | ConferÃªncia e revisÃ£o rÃ¡pida. Arquivo: **[Raw Data](https://raw.githubusercontent.com/gyamada22/Job-Market-Analysis/main/data/Vagas_Coletadas_Raw.xlsx)** |
| Limpeza e padronizaÃ§Ã£o | Python | Padroniza dados, corrige inconsistÃªncias e gera Excel/SQL. Arquivo: **[Cleaned Data](https://raw.githubusercontent.com/gyamada22/Job-Market-Analysis/main/data/Vagas_Coletadas_Cleaned.xlsx)**, Script: **[ETL.py](https://github.com/gyamada22/Job-Market-Analysis/blob/main/data/ETL.py)** |
| Modelagem e anÃ¡lise | SQL | CriaÃ§Ã£o de tabelas, views e queries analÃ­ticas *(em desenvolvimento)* |
| Dashboards | Power BI | VisualizaÃ§Ã£o interativa, insights e storytelling |
| DocumentaÃ§Ã£o | GitHub | Registro completo do projeto, metodologia e exemplos de dashboards |

> ğŸ’¡ ObservaÃ§Ã£o: Python permite **automatizar toda a cadeia de transformaÃ§Ã£o**, tornando o fluxo de dados mais eficiente e escalÃ¡vel do que usar Excel para limpeza manual.

---

## ğŸ¯ Objetivos
- Coletar dados de vagas reais: empresa, cargo, localizaÃ§Ã£o, data, nÃ­vel de senioridade e requisitos tÃ©cnicos.  
- Padronizar e estruturar dados textuais nÃ£o estruturados (descriÃ§Ãµes de vagas).  
- Identificar **skills mais demandadas** por Ã¡rea e nÃ­vel (estÃ¡gio, jÃºnior, pleno, sÃªnior).  
- Analisar **diferenÃ§as e gaps de competÃªncias** entre nÃ­veis de senioridade.  
- Comparar o mercado brasileiro com dados internacionais para identificar **tendÃªncias emergentes**.  
- Criar dashboards interativos que apoiem **decisÃµes de carreira e estudo**.  
- Documentar todo o pipeline: **coleta â†’ limpeza â†’ anÃ¡lise â†’ visualizaÃ§Ã£o**.

---

## âœ… Status Atual
- [x] Estrutura de pastas criada  
- [x] Coleta de dados inicial 
- [ ] Modelagem do banco de dados  
- [ ] Primeiras anÃ¡lises  
- [ ] Dashboard inicial  

---

## ğŸ”¹ ObservaÃ§Ãµes Finais
- Pipeline eficiente, contornando limitaÃ§Ãµes do LinkedIn  
- Uso integrado de IA, Python, SQL, Power BI e Excel
- DocumentaÃ§Ã£o clara, garantindo transparÃªncia e profissionalismo para portfÃ³lio
